{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a2f85f-d580-4b1a-9ba9-de0f3ed89261",
   "metadata": {},
   "source": [
    "# Module 2 â€“ In-Class Exercise\n",
    "Working with Text in Python (Instructor Version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a94f174-4de5-4731-ab96-145e14a495f1",
   "metadata": {},
   "source": [
    "# Module 2 â€“ In-Class Exercise\n",
    "## Working with Text in Python\n",
    "\n",
    "### Learning Objectives\n",
    "- Use Python string methods for text manipulation\n",
    "- Handle text encoding issues\n",
    "- Normalize text for preprocessing\n",
    "- Prepare raw text for analysis\n",
    "\n",
    "Complete all tasks below. Show your code and output for each section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058d5f1-a8fd-4c34-848c-a2cc227e942a",
   "metadata": {},
   "source": [
    "## Part 1 â€“ Basic String Operations\n",
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd98032-9be8-41ca-a8b9-63c35542931b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Python is AMAZING!! Python is powerful, flexible, and FUN.   '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"  Python is AMAZING!! Python is powerful, flexible, and FUN.   \"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89479f82-4854-45af-be67-1e35fc947bde",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Remove leading and trailing whitespace.\n",
    "2. Convert the entire string to lowercase.\n",
    "3. Replace \"AMAZING!!\" with \"amazing\".\n",
    "4. Count how many times the word \"python\" appears.\n",
    "5. Split the sentence into individual words.\n",
    "6. Remove punctuation from the string.\n",
    "\n",
    "Write your code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab05619-ba4f-484d-8f11-7799bb56ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed text: Python is AMAZING!! Python is powerful, flexible, and FUN.\n",
      "Lowercase: python is amazing!! python is powerful, flexible, and fun.\n",
      "Replaced text: python is amazing python is powerful, flexible, and fun.\n",
      "Count of 'python': 2\n",
      "Words: ['python', 'is', 'amazing', 'python', 'is', 'powerful,', 'flexible,', 'and', 'fun.']\n",
      "Text without punctuation: python is amazing python is powerful flexible and fun\n"
     ]
    }
   ],
   "source": [
    "# Your code here (Sample Answer)\n",
    "text = \"  Python is AMAZING!! Python is powerful, flexible, and FUN.   \"\n",
    "\n",
    "# 1. Remove leading and trailing whitespace\n",
    "text_clean = text.strip()\n",
    "print(\"Trimmed text:\", text_clean)\n",
    "\n",
    "# 2. Convert the entire string to lowercase\n",
    "text_lower = text_clean.lower()\n",
    "print(\"Lowercase:\", text_lower)\n",
    "\n",
    "# 3. Replace \"AMAZING!!\" with \"amazing\"\n",
    "text_replaced = text_lower.replace(\"amazing!!\", \"amazing\")\n",
    "print(\"Replaced text:\", text_replaced)\n",
    "\n",
    "# 4. Count how many times the word \"python\" appears\n",
    "count_python = text_replaced.count(\"python\")\n",
    "print(\"Count of 'python':\", count_python)\n",
    "\n",
    "# 5. Split the sentence into individual words\n",
    "words = text_replaced.split()\n",
    "print(\"Words:\", words)\n",
    "\n",
    "# 6. Remove punctuation from the string\n",
    "import string\n",
    "text_no_punct = text_replaced.translate(str.maketrans('', '', string.punctuation))\n",
    "print(\"Text without punctuation:\", text_no_punct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57f97b-a0fc-4306-b313-913abafdd7e3",
   "metadata": {},
   "source": [
    "### Removing Punctuation in Python with `str.translate()` and `str.maketrans()`\n",
    "\n",
    "In text preprocessing, itâ€™s common to remove punctuation from strings so that words can be analyzed cleanly. Python provides a simple way to do this using `str.translate()` and `str.maketrans()`.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "```python\n",
    "import string\n",
    "\n",
    "text = \"Hello, world! Python is fun.\"\n",
    "# Remove punctuation\n",
    "clean_text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "print(clean_text)\n",
    "\n",
    "# How It Works:\n",
    "\n",
    "string.punctuation\n",
    "\n",
    "A pre-defined string containing all punctuation characters:\n",
    "\n",
    "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "\n",
    "\n",
    "These are the characters we want to remove from our text.\n",
    "\n",
    "str.maketrans('', '', string.punctuation)\n",
    "\n",
    "str.maketrans(x, y, z) creates a translation table:\n",
    "\n",
    "x â†’ characters to replace\n",
    "\n",
    "y â†’ characters to replace with\n",
    "\n",
    "z â†’ characters to delete\n",
    "\n",
    "Here, x='' and y='' â†’ we do not replace any characters.\n",
    "\n",
    "z=string.punctuation â†’ delete all punctuation characters.\n",
    "\n",
    "text.translate(...)\n",
    "\n",
    "Applies the translation table to the string.\n",
    "\n",
    "Removes all characters listed in z (punctuation), keeping letters, numbers, and spaces intact.\n",
    "\n",
    "# Why is this useful in text mining?\n",
    "\n",
    "Ensures that punctuation does not interfere with tokenization or word counts.\n",
    "\n",
    "Standardizes text for analysis, making operations like lowercasing, stemming, or vectorization more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5aa0c-7e5d-4837-ab6b-91897efffa9f",
   "metadata": {},
   "source": [
    "## Part 2 â€“ Advanced String Manipulation\n",
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c4943f4-95ab-48bf-8ac2-bf6b51ec465b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Science, data science, DATA science!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Data Science, data science, DATA science!\"\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0677620-87c2-4e9b-bc64-6d435c700196",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Normalize the text so all variations become identical.\n",
    "2. Remove duplicate words.\n",
    "3. Output the cleaned sentence as:\n",
    "\n",
    "data science\n",
    "\n",
    "Optional Challenge:\n",
    "- Use a set to remove duplicates while preserving word order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2274ba8b-75dc-426a-b951-6295b6b697fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned sentence: data science\n"
     ]
    }
   ],
   "source": [
    "# Your code here (Sample Answer)\n",
    "sentence = \"Data Science, data science, DATA science!\"\n",
    "\n",
    "# 1. Normalize the text so all variations become identical\n",
    "sentence_lower = sentence.lower()\n",
    "\n",
    "# 2. Remove punctuation\n",
    "sentence_clean = sentence_lower.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# 3. Split into words\n",
    "words = sentence_clean.split()\n",
    "\n",
    "# 4. Remove duplicates while preserving order\n",
    "seen = set()\n",
    "unique_words = []\n",
    "for word in words:\n",
    "    if word not in seen:\n",
    "        unique_words.append(word)\n",
    "        seen.add(word)\n",
    "\n",
    "# 5. Join words to produce cleaned sentence\n",
    "cleaned_sentence = \" \".join(unique_words)\n",
    "print(\"Cleaned sentence:\", cleaned_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ccab3c-f1fb-4f4a-8d30-ae9cb5a8449d",
   "metadata": {},
   "source": [
    "# Text Normalization â€“ In-Class Demonstration\n",
    "\n",
    "## What is Text Normalization?\n",
    "\n",
    "Text normalization is the process of **transforming text into a standard, consistent format** so it can be analyzed more easily.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- Words can appear in many forms (e.g., `\"Data\"`, `\"data\"`, `\"DATA\"`). Normalization treats them as the same.\n",
    "- Text may include extra spaces, punctuation, emojis, or repeated characters.\n",
    "- Normalization prepares raw text for **tokenization, word counting, machine learning, or NLP tasks**.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "| Original Text                  | Normalized Text        |\n",
    "|--------------------------------|----------------------|\n",
    "| `\"Data Science, data science\"` | `\"data science data science\"` |\n",
    "| `\"I LOVED this movie!!!\"`      | `\"i loved this movie\"` |\n",
    "| `\"CafÃ© MÃ¼nster\"`               | `\"cafÃ© mÃ¼nster\"`       |\n",
    "\n",
    "---\n",
    "\n",
    "## Why Normalization Matters\n",
    "\n",
    "- **Consistency:** Avoid treating `\"Python\"` and `\"python\"` as different words.\n",
    "- **Reduces noise:** Punctuation, extra spaces, or repeated characters do not interfere with analysis.\n",
    "- **Reliable feature extraction:** Vectorization, word counts, and sentiment analysis work better on clean text.\n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Demonstration in Python\n",
    "\n",
    "### Step 1: Start with messy text\n",
    "```python\n",
    "raw_text = \"I LOVED this movie!!! It was soooo good!!! ðŸ˜„ðŸ˜„\"\n",
    "print(raw_text)\n",
    "```\n",
    "*Output:*  \n",
    "```\n",
    "I LOVED this movie!!! It was soooo good!!! ðŸ˜„ðŸ˜„\n",
    "```\n",
    "\n",
    "### Step 2: Convert to lowercase\n",
    "```python\n",
    "text_lower = raw_text.lower()\n",
    "print(text_lower)\n",
    "```\n",
    "*Output:*  \n",
    "```\n",
    "i loved this movie!!! it was soooo good!!! ðŸ˜„ðŸ˜„\n",
    "```\n",
    "- All words are now lowercase.\n",
    "\n",
    "### Step 3: Remove punctuation\n",
    "```python\n",
    "import string\n",
    "text_no_punct = text_lower.translate(str.maketrans('', '', string.punctuation))\n",
    "print(text_no_punct)\n",
    "```\n",
    "*Output:*  \n",
    "```\n",
    "i loved this movie it was soooo good ðŸ˜„ðŸ˜„\n",
    "```\n",
    "- Punctuation like `!!!` is removed.\n",
    "\n",
    "### Step 4: Reduce repeated characters\n",
    "```python\n",
    "import re\n",
    "text_normalized = re.sub(r'(.)\\1{2,}', r'\\1\\1', text_no_punct)\n",
    "print(text_normalized)\n",
    "```\n",
    "*Output:*  \n",
    "```\n",
    "i loved this movie it was soo good ðŸ˜„ðŸ˜„\n",
    "```\n",
    "- `\"soooo\"` â†’ `\"soo\"` to standardize text.\n",
    "\n",
    "### Step 5: Remove emojis (optional)\n",
    "```python\n",
    "text_clean = text_normalized.encode('ascii', 'ignore').decode('ascii')\n",
    "print(text_clean)\n",
    "```\n",
    "*Output:*  \n",
    "```\n",
    "i loved this movie it was soo good\n",
    "```\n",
    "- Non-ASCII characters like emojis are removed.\n",
    "\n",
    "---\n",
    "\n",
    "## practice for Students\n",
    "\n",
    "- **Questions:**\n",
    "  - \"What would happen if we skip lowercase conversion?\"  \n",
    "  - \"How might repeated characters affect sentiment analysis?\"  \n",
    "- **Hands-On:** Let normalize your own example sentences.  \n",
    "- **Reflection:** Consider what information might be lost during normalization (emphasis, emojis, special punctuation).\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Summary\n",
    "\n",
    "**Normalization Steps in Practice:**\n",
    "\n",
    "1. Convert text to lowercase.\n",
    "2. Remove punctuation.\n",
    "3. Remove extra whitespace.\n",
    "4. Reduce repeated characters.\n",
    "5. Remove or standardize non-standard characters (e.g., emojis, accented letters).\n",
    "\n",
    "Note: Clean, normalized text is ready for NLP analysis, feature extraction, and machine learning workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fb3d3-1c1c-4c86-9454-02ca5f5b970f",
   "metadata": {},
   "source": [
    "## Part 3 â€“ Text Encoding\n",
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0196d196-a774-4531-b457-0b7740ab7045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CafÃ© MÃ¼nster â€” naÃ¯ve faÃ§ade'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"CafÃ© MÃ¼nster â€” naÃ¯ve faÃ§ade\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1280a9-3026-47f7-9870-8fe31c7748dd",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Print the text normally.\n",
    "2. Encode the string in UTF-8.\n",
    "3. Decode it back to readable format.\n",
    "4. Attempt ASCII encoding. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7571101b-b48c-4cd6-9b40-a0fd656bffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: CafÃ© MÃ¼nster â€” naÃ¯ve faÃ§ade\n",
      "UTF-8 encoded: b'Caf\\xc3\\xa9 M\\xc3\\xbcnster \\xe2\\x80\\x94 na\\xc3\\xafve fa\\xc3\\xa7ade'\n",
      "Decoded text: CafÃ© MÃ¼nster â€” naÃ¯ve faÃ§ade\n",
      "ASCII encoding error: 'ascii' codec can't encode character '\\xe9' in position 3: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "# Your code here (Sample Answer)\n",
    "text = \"CafÃ© MÃ¼nster â€” naÃ¯ve faÃ§ade\"\n",
    "\n",
    "# 1. Print the text normally\n",
    "print(\"Original text:\", text)\n",
    "\n",
    "# 2. Encode the string in UTF-8\n",
    "utf8_encoded = text.encode('utf-8')\n",
    "print(\"UTF-8 encoded:\", utf8_encoded)\n",
    "\n",
    "# 3. Decode it back to readable format\n",
    "utf8_decoded = utf8_encoded.decode('utf-8')\n",
    "print(\"Decoded text:\", utf8_decoded)\n",
    "\n",
    "# 4. Attempt ASCII encoding (will fail on non-ASCII chars)\n",
    "try:\n",
    "    ascii_encoded = text.encode('ascii')\n",
    "    print(\"ASCII encoded:\", ascii_encoded)\n",
    "except UnicodeEncodeError as e:\n",
    "    print(\"ASCII encoding error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e6d12-eb3a-4967-b288-047a1ef0e9ff",
   "metadata": {},
   "source": [
    "# Text Encoding and Decoding â€“ In-Class Demonstration\n",
    "\n",
    "## What is Text Encoding?\n",
    "\n",
    "Text encoding is the process of converting characters into bytes so that computers can store or transmit text.\n",
    "\n",
    "- **UTF-8:** Can represent almost all characters from all languages.\n",
    "- **ASCII:** Only represents 128 basic characters (English letters, digits, and some symbols).\n",
    "- Encoding ensures text can be stored or sent, while decoding converts it back to readable form.\n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Example\n",
    "\n",
    "### Sample Text\n",
    "```python\n",
    "text = \"CafÃ© MÃ¼nster â€” naÃ¯ve faÃ§ade\"\n",
    "print(text)\n",
    "```\n",
    "*Output:*  \n",
    "```\n",
    "CafÃ© MÃ¼nster â€” naÃ¯ve faÃ§ade\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Encode in UTF-8\n",
    "```python\n",
    "utf8_bytes = text.encode('utf-8')\n",
    "print(utf8_bytes)\n",
    "```\n",
    "*Output (bytes):*  \n",
    "```\n",
    "b'Caf\\xc3\\xa9 M\\xc3\\xbcnster \\xe2\\x80\\x94 na\\xefve fa\\xc3\\xa7ade'\n",
    "```\n",
    "- UTF-8 converts each character into bytes.  \n",
    "- Non-ASCII characters like `Ã©`, `Ã¼`, `â€”`, `Ã§` are represented as multiple bytes.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Decode back to readable text\n",
    "```python\n",
    "decoded_text = utf8_bytes.decode('utf-8')\n",
    "print(decoded_text)\n",
    "```\n",
    "*Output:*  \n",
    "```\n",
    "CafÃ© MÃ¼nster â€” naÃ¯ve faÃ§ade\n",
    "```\n",
    "- Decoding converts the bytes back into human-readable text.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Attempt ASCII encoding\n",
    "```python\n",
    "ascii_bytes = text.encode('ascii')\n",
    "```\n",
    "- **Result:** Python raises a `UnicodeEncodeError` because ASCII cannot represent characters like `Ã©`, `Ã¼`, `â€”`, `Ã§`.  \n",
    "\n",
    "**Explanation:**  \n",
    "- ASCII supports only basic English letters, digits, and some punctuation.  \n",
    "- Non-English or special characters cannot be encoded in ASCII without data loss.  \n",
    "- You could handle this with options like `errors='ignore'` or `errors='replace'` if needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Encoding** converts text to bytes for storage or transmission.  \n",
    "2. **UTF-8** can handle almost all characters; **ASCII** is very limited.  \n",
    "3. **Decoding** is necessary to convert bytes back to readable text.  \n",
    "4. Use UTF-8 for text mining and NLP to avoid errors with special characters.\n",
    "\n",
    "---\n",
    "\n",
    "## Optional Demo: ASCII with error handling\n",
    "```python\n",
    "ascii_bytes_safe = text.encode('ascii', errors='ignore')\n",
    "ascii_text_safe = ascii_bytes_safe.decode('ascii')\n",
    "print(ascii_text_safe)\n",
    "```\n",
    "*Output:*  \n",
    "```\n",
    "Caf Mnster  nave faade\n",
    "```\n",
    "- Non-ASCII characters are removed, which may **cause data loss**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26b4d21-a142-420d-8566-29b72776cc89",
   "metadata": {},
   "source": [
    "## Part 4 â€“ Text Normalization\n",
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07c03c5f-81d5-4103-9ac4-536e5c83298c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I LOVED this movie!!! It was soooo good!!! ðŸ˜„ðŸ˜„'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = \"I LOVED this movie!!! It was soooo good!!! ðŸ˜„ðŸ˜„\"\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66617966-0439-45fd-9168-7b8d0230df71",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Convert text to lowercase.\n",
    "2. Remove repeated exclamation marks.\n",
    "3. Remove emojis (basic method).\n",
    "4. Reduce repeated characters (e.g., \"soooo\" â†’ \"so\").\n",
    "5. Output a cleaned version suitable for analysis.\n",
    "\n",
    "Bonus:\n",
    "- Use regular expressions (re) to reduce repeated characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c0fda8-57ec-43b8-bc6f-ef220f285d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text: i loved this movie! it was soo good!\n"
     ]
    }
   ],
   "source": [
    "# Your code here (Sample Answer)\n",
    "\n",
    "import re\n",
    "\n",
    "raw_text = \"I LOVED this movie!!! It was soooo good!!! ðŸ˜„ðŸ˜„\"\n",
    "\n",
    "# 1. Convert text to lowercase\n",
    "text_lower = raw_text.lower()\n",
    "\n",
    "# 2. Remove repeated exclamation marks\n",
    "text_no_exclaim = re.sub(r'!+', '!', text_lower)\n",
    "\n",
    "# 3. Remove emojis (basic method: remove non-ASCII characters)\n",
    "text_no_emoji = text_no_exclaim.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "# 4. Reduce repeated characters (e.g., \"soooo\" â†’ \"so\")\n",
    "text_normalized = re.sub(r'(.)\\1{2,}', r'\\1\\1', text_no_emoji)\n",
    "\n",
    "# 5. Output cleaned version\n",
    "cleaned_text = text_normalized.strip()\n",
    "print(\"Cleaned text:\", cleaned_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b0b3f-c7dc-4fc6-991b-1eb16971ba27",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. Why is normalization important before text analysis?\n",
    "2. What information might be lost during cleaning?\n",
    "3. When might you not want to normalize aggressively?\n",
    "\n",
    "Write 3â€“5 sentences below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc7e25-bf91-4272-8ba6-e74ecdd203ef",
   "metadata": {},
   "source": [
    "# Your Reflection Answer (Sample Answer)\n",
    "\n",
    "1. Normalization is important because text can have inconsistent capitalization, punctuation, or repeated characters. Normalization ensures that analysis (like word counts or tokenization) is accurate.\n",
    "\n",
    "2. Some information might be lost, e.g., emojis, punctuation, or emphasis from repeated letters.\n",
    "\n",
    "3. Aggressive normalization may not be desirable if the original text style carries meaning, such as sentiment in social media posts or literary emphasis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b21496-32fb-4c14-9442-8bf50683654c",
   "metadata": {},
   "source": [
    "# Your response here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4042e-d872-4b3b-b701-598b0ff35458",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "- Ensure all cells run without errors.\n",
    "- Display outputs for each section.\n",
    "- Include written reflection answers.\n",
    "- Submit the completed notebook (.ipynb) to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (textmining-env)",
   "language": "python",
   "name": "textmining-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
